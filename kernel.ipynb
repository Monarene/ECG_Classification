{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy.signal import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Softmax, Add, Flatten, Activation# , Dropout\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/mitbih_train.csv\", header=None)\n",
    "df2 = pd.read_csv(\"../input/mitbih_test.csv\", header=None)\n",
    "df = pd.concat([df, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "494fc8a26ba40beb73fc1a4f7b219b213fb7705e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5281cb19f54f3bd379f875c24ae52b3b15fcafaf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0fac0fb658ea34b48055838b4ad85078e883360d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[187].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "147b7604bd8a389d7f6aa111f38ae308af7c4eb7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = df.values\n",
    "X = M[:, :-1]\n",
    "y = M[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "504d95532114efa4cc581d80bf02159c3ce519c6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df\n",
    "del df2\n",
    "del M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "425c4b7abe39a14c6f81f8a71094cc1024276935"
   },
   "source": [
    "# Visual Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcd502ecd1eb95bbf8af983396d3d0c3fb50ce4b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C0 = np.argwhere(y == 0).flatten()\n",
    "C1 = np.argwhere(y == 1).flatten()\n",
    "C2 = np.argwhere(y == 2).flatten()\n",
    "C3 = np.argwhere(y == 3).flatten()\n",
    "C4 = np.argwhere(y == 4).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85209065f110cea77f4d65053d1164e9ee816049",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(0, 187)*8/1000\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(x, X[C0, :][0], label=\"Cat. N\")\n",
    "plt.plot(x, X[C1, :][0], label=\"Cat. S\")\n",
    "plt.plot(x, X[C2, :][0], label=\"Cat. V\")\n",
    "plt.plot(x, X[C3, :][0], label=\"Cat. F\")\n",
    "plt.plot(x, X[C4, :][0], label=\"Cat. Q\")\n",
    "plt.legend()\n",
    "plt.title(\"1-beat ECG for every category\", fontsize=20)\n",
    "plt.ylabel(\"Amplitude\", fontsize=15)\n",
    "plt.xlabel(\"Time (ms)\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c269ab78773e4b5a960a5e55d2b48c53d5f9c446"
   },
   "source": [
    "# Data augmentation\n",
    "\n",
    "To train properly the model, we sould have to augment all data to the same level. Nevertheless, for a first try, we will just augment the smallest class to the same level as class 1. With that we will be able to have a test set of around 5x800 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a332bfa2765ee6f5d49320c9d8f0b9c5795a4843",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stretch(x):\n",
    "    l = int(187 * (1 + (random.random()-0.5)/3))\n",
    "    y = resample(x, l)\n",
    "    if l < 187:\n",
    "        y_ = np.zeros(shape=(187, ))\n",
    "        y_[:l] = y\n",
    "    else:\n",
    "        y_ = y[:187]\n",
    "    return y_\n",
    "\n",
    "def amplify(x):\n",
    "    alpha = (random.random()-0.5)\n",
    "    factor = -alpha*x + (1+alpha)\n",
    "    return x*factor\n",
    "\n",
    "def augment(x):\n",
    "    result = np.zeros(shape= (4, 187))\n",
    "    for i in range(3):\n",
    "        if random.random() < 0.33:\n",
    "            new_y = stretch(x)\n",
    "        elif random.random() < 0.66:\n",
    "            new_y = amplify(x)\n",
    "        else:\n",
    "            new_y = stretch(x)\n",
    "            new_y = amplify(new_y)\n",
    "        result[i, :] = new_y\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8673145476e0307f487a502e3590b76f2589acef",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(X[0, :])\n",
    "plt.plot(amplify(X[0, :]))\n",
    "plt.plot(stretch(X[0, :]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "43f671858db58465b14b7fd7656ffa8381f7ea86",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = np.apply_along_axis(augment, axis=1, arr=X[C3]).reshape(-1, 187)\n",
    "classe = np.ones(shape=(result.shape[0],), dtype=int)*3\n",
    "X = np.vstack([X, result])\n",
    "y = np.hstack([y, classe])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c42605d020fd51885437f4af3cf10cebbeafc9bb"
   },
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c136b567ed0cf450ed0476464c3b59d1ff1bb032",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subC0 = np.random.choice(C0, 800)\n",
    "subC1 = np.random.choice(C1, 800)\n",
    "subC2 = np.random.choice(C2, 800)\n",
    "subC3 = np.random.choice(C3, 800)\n",
    "subC4 = np.random.choice(C4, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52573d0c3a715cd693e682227d01f5a73549e421",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.vstack([X[subC0], X[subC1], X[subC2], X[subC3], X[subC4]])\n",
    "y_test = np.hstack([y[subC0], y[subC1], y[subC2], y[subC3], y[subC4]])\n",
    "\n",
    "X_train = np.delete(X, [subC0, subC1, subC2, subC3, subC4], axis=0)\n",
    "y_train = np.delete(y, [subC0, subC1, subC2, subC3, subC4], axis=0)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=0)\n",
    "\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ae5108c9741b85f0f599cce51daf99df4733ed1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, 2)\n",
    "X_test = np.expand_dims(X_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbd350e57b2a44b4bf6a79f02c32dabb803e4855",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ddf1e7b397de3c413fc991945d2d7f09df67da1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "y_train = ohe.fit_transform(y_train.reshape(-1,1))\n",
    "y_test = ohe.transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16c106c2702045790367fc49d7223560fc613d75",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4de23b85abe34a726eab268171da0e827bafa35"
   },
   "source": [
    "# Model\n",
    "\n",
    "Now let's re-create the model from the ArXiv Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb0dc9775ddfa761c0ad948d59020fcbd2681c57",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_obs, feature, depth = X_train.shape\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e70fab0b07290e042ba9cd7c6cba37462a457b03",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inp = Input(shape=(feature, depth))\n",
    "C = Conv1D(filters=32, kernel_size=5, strides=1)(inp)\n",
    "\n",
    "C11 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(C)\n",
    "A11 = Activation(\"relu\")(C11)\n",
    "C12 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A11)\n",
    "S11 = Add()([C12, C])\n",
    "A12 = Activation(\"relu\")(S11)\n",
    "M11 = MaxPooling1D(pool_size=5, strides=2)(A12)\n",
    "\n",
    "\n",
    "C21 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M11)\n",
    "A21 = Activation(\"relu\")(C21)\n",
    "C22 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A21)\n",
    "S21 = Add()([C22, M11])\n",
    "A22 = Activation(\"relu\")(S11)\n",
    "M21 = MaxPooling1D(pool_size=5, strides=2)(A22)\n",
    "\n",
    "\n",
    "C31 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M21)\n",
    "A31 = Activation(\"relu\")(C31)\n",
    "C32 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A31)\n",
    "S31 = Add()([C32, M21])\n",
    "A32 = Activation(\"relu\")(S31)\n",
    "M31 = MaxPooling1D(pool_size=5, strides=2)(A32)\n",
    "\n",
    "\n",
    "C41 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M31)\n",
    "A41 = Activation(\"relu\")(C41)\n",
    "C42 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A41)\n",
    "S41 = Add()([C42, M31])\n",
    "A42 = Activation(\"relu\")(S41)\n",
    "M41 = MaxPooling1D(pool_size=5, strides=2)(A42)\n",
    "\n",
    "\n",
    "C51 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M41)\n",
    "A51 = Activation(\"relu\")(C51)\n",
    "C52 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A51)\n",
    "S51 = Add()([C52, M41])\n",
    "A52 = Activation(\"relu\")(S51)\n",
    "M51 = MaxPooling1D(pool_size=5, strides=2)(A52)\n",
    "\n",
    "F1 = Flatten()(M51)\n",
    "\n",
    "D1 = Dense(32)(F1)\n",
    "A6 = Activation(\"relu\")(D1)\n",
    "D2 = Dense(32)(A6)\n",
    "D3 = Dense(5)(D2)\n",
    "A7 = Softmax()(D3)\n",
    "\n",
    "model = Model(inputs=inp, outputs=A7)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fdc0d8aa8475330af8d8e652d0b9ce214da66956",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    k = 0.75\n",
    "    t = n_obs//(10000 * batch_size)  # every epoch we do n_obs/batch_size iteration\n",
    "    lrate = initial_lrate * math.exp(-k*t)\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(exp_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abcd2f0e8488c8f3b33cd6ed9ca7fd60fa44404b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "812e637ae56f6a4be9c8e98d3b501cfb11ef78cb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e6ef643f6a55ab5b3c1b46126832c3ac45a6a2b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=75, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d43023d26a87e3c4702b96bea5962c990c76aa0a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "20cfe7f5891e3c26c599fa4cd728ac0a499ac70e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "017f2431a45766fb0d4b2ef17ce613c1142ca085",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"ranking-based average precision : {:.3f}\".format(label_ranking_average_precision_score(y_test.todense(), y_pred)))\n",
    "print(\"Ranking loss : {:.3f}\".format(label_ranking_loss(y_test.todense(), y_pred)))\n",
    "print(\"Coverage_error : {:.3f}\".format(coverage_error(y_test.todense(), y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0fcf027f00a7031dd7dc7d25c0c6ff362c39954b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
